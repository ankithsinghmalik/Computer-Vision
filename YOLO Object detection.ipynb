{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dependencies\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 800, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading the image\n",
    "image = cv2.imread(\"Pictures\\pedestrain.jpg\")\n",
    "image = cv2.resize(image,(800,800))\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "height,width,_ = image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"image\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the configuration files and weights of yolov3\n",
    "net = cv2.dnn.readNet(\"C:/Users/mvcc1/darknet/cfg/yolov3.cfg\",'C:/Users/mvcc1/Downloads/yolov3.weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the classes on what all the yolo algorithm has been trained on\n",
    "classes = []\n",
    "with open('C:/Users/mvcc1/darknet/data/coco.names','r') as f:\n",
    "    classes = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person',\n",
       " 'bicycle',\n",
       " 'car',\n",
       " 'motorbike',\n",
       " 'aeroplane',\n",
       " 'bus',\n",
       " 'train',\n",
       " 'truck',\n",
       " 'boat',\n",
       " 'traffic light',\n",
       " 'fire hydrant',\n",
       " 'stop sign',\n",
       " 'parking meter',\n",
       " 'bench',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'dog',\n",
       " 'horse',\n",
       " 'sheep',\n",
       " 'cow',\n",
       " 'elephant',\n",
       " 'bear',\n",
       " 'zebra',\n",
       " 'giraffe',\n",
       " 'backpack',\n",
       " 'umbrella',\n",
       " 'handbag',\n",
       " 'tie',\n",
       " 'suitcase',\n",
       " 'frisbee',\n",
       " 'skis',\n",
       " 'snowboard',\n",
       " 'sports ball',\n",
       " 'kite',\n",
       " 'baseball bat',\n",
       " 'baseball glove',\n",
       " 'skateboard',\n",
       " 'surfboard',\n",
       " 'tennis racket',\n",
       " 'bottle',\n",
       " 'wine glass',\n",
       " 'cup',\n",
       " 'fork',\n",
       " 'knife',\n",
       " 'spoon',\n",
       " 'bowl',\n",
       " 'banana',\n",
       " 'apple',\n",
       " 'sandwich',\n",
       " 'orange',\n",
       " 'broccoli',\n",
       " 'carrot',\n",
       " 'hot dog',\n",
       " 'pizza',\n",
       " 'donut',\n",
       " 'cake',\n",
       " 'chair',\n",
       " 'sofa',\n",
       " 'pottedplant',\n",
       " 'bed',\n",
       " 'diningtable',\n",
       " 'toilet',\n",
       " 'tvmonitor',\n",
       " 'laptop',\n",
       " 'mouse',\n",
       " 'remote',\n",
       " 'keyboard',\n",
       " 'cell phone',\n",
       " 'microwave',\n",
       " 'oven',\n",
       " 'toaster',\n",
       " 'sink',\n",
       " 'refrigerator',\n",
       " 'book',\n",
       " 'clock',\n",
       " 'vase',\n",
       " 'scissors',\n",
       " 'teddy bear',\n",
       " 'hair drier',\n",
       " 'toothbrush']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing the image\n",
    "blob = cv2.dnn.blobFromImage(image,1/255,(416,416),(0,0,0),swapRB=True,crop=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in blob:\n",
    "    for n, img in enumerate(each):\n",
    "        cv2.imshow(str(n),img)\n",
    "        cv2.waitKey(1000)\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.setInput(blob)\n",
    "outputLayerNames = net.getUnconnectedOutLayersNames()\n",
    "layerOutputs = net.forward(outputLayerNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.03332959, 0.05110101, 0.4849458 , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.04233668, 0.03517634, 0.31936866, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.04612767, 0.03914372, 0.78570557, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       ...,\n",
      "       [0.9622269 , 0.9589328 , 0.4172877 , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.9594379 , 0.96294284, 0.31359497, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.9692155 , 0.9699744 , 0.8512954 , ..., 0.        , 0.        ,\n",
      "        0.        ]], dtype=float32), array([[0.02130396, 0.02054469, 0.05499898, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.01455568, 0.01959859, 0.33662814, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.01896849, 0.01693274, 0.07978649, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       ...,\n",
      "       [0.97766316, 0.97976804, 0.03736178, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.98236305, 0.98388857, 0.41989896, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.9799561 , 0.9820659 , 0.0649493 , ..., 0.        , 0.        ,\n",
      "        0.        ]], dtype=float32), array([[0.00970186, 0.00726663, 0.01293135, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.01020047, 0.01112438, 0.02332474, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.01046917, 0.00875092, 0.18645336, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       ...,\n",
      "       [0.992768  , 0.99310464, 0.01295068, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.99336314, 0.98903286, 0.01299765, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.9897856 , 0.9929445 , 0.20763685, ..., 0.        , 0.        ,\n",
      "        0.        ]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(layerOutputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[443, 86, 118, 68], [442, 90, 122, 68], [623, 172, 66, 82], [615, 171, 81, 84], [203, 188, 58, 76], [625, 180, 63, 76], [617, 180, 78, 76], [215, 329, 42, 122], [115, 359, 50, 107], [218, 355, 46, 120], [290, 370, 49, 98], [360, 364, 44, 106], [417, 364, 41, 126], [513, 371, 44, 101], [551, 364, 44, 90], [612, 368, 45, 108], [53, 378, 39, 124], [106, 402, 59, 79], [91, 407, 85, 74], [228, 395, 53, 88], [419, 380, 42, 110], [508, 382, 49, 120], [2, 422, 34, 125], [187, 416, 41, 121], [272, 428, 98, 73], [482, 429, 98, 80], [576, 425, 55, 86], [1, 429, 34, 135], [335, 453, 60, 103], [342, 457, 58, 99], [335, 493, 59, 102], [748, 485, 49, 101], [336, 513, 55, 85], [640, 74, 33, 50], [215, 136, 51, 55], [621, 178, 66, 72], [200, 188, 58, 71], [203, 189, 60, 68], [620, 178, 67, 77], [121, 219, 29, 95], [448, 237, 24, 99], [450, 237, 26, 99], [300, 286, 10, 24], [300, 265, 23, 94], [455, 287, 19, 58], [171, 296, 19, 62], [208, 285, 26, 99], [208, 295, 24, 93], [711, 298, 22, 100], [713, 298, 21, 100], [321, 380, 21, 36], [315, 377, 27, 42], [563, 362, 30, 71], [561, 362, 32, 81], [101, 421, 63, 58], [107, 420, 70, 61]]\n",
      "[0.9154288172721863, 0.8447436690330505, 0.9792284965515137, 0.8807653784751892, 0.9542388916015625, 0.9876989126205444, 0.9595457911491394, 0.6816245913505554, 0.965484619140625, 0.6892898678779602, 0.9800639152526855, 0.9664050340652466, 0.948635995388031, 0.8301740884780884, 0.7492017149925232, 0.8202189207077026, 0.9894626140594482, 0.5598525404930115, 0.6346646547317505, 0.789101243019104, 0.9645674228668213, 0.513776421546936, 0.8119515776634216, 0.9853992462158203, 0.6130513548851013, 0.8789289593696594, 0.655213475227356, 0.5508884191513062, 0.8343852758407593, 0.7364774942398071, 0.8748178482055664, 0.608594536781311, 0.8164523839950562, 0.6529258489608765, 0.8565966486930847, 0.6948357820510864, 0.9007166624069214, 0.9861076474189758, 0.9625610113143921, 0.6667521595954895, 0.7884621620178223, 0.9451826810836792, 0.5844510793685913, 0.9843980073928833, 0.6741560697555542, 0.8797305822372437, 0.7288371920585632, 0.7867401838302612, 0.9434472918510437, 0.9372779130935669, 0.6668380498886108, 0.5699117183685303, 0.6588430404663086, 0.7442457675933838, 0.5559942126274109, 0.6356334090232849]\n",
      "[16  5 37 23 43 10 11  8 20 41 48  0 45 25 30 34 13 15 22 19 47 14 29  9\n",
      " 44 50 39 26 33 55 24 31 42]\n"
     ]
    }
   ],
   "source": [
    "#storing the final output of bounding box and classes and confidence of the object detected by yolo in the image\n",
    "boxes = []\n",
    "confidences = []\n",
    "class_ids = []\n",
    "\n",
    "for each in layerOutputs:\n",
    "    for detection in each:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.5:\n",
    "            center_x = int(detection[0] * width)\n",
    "            center_y = int(detection[1] * height)\n",
    "            w = int(detection[2]*width)\n",
    "            h = int(detection[3]*height)\n",
    "            \n",
    "            x = int(center_x - (w/2))\n",
    "            y = int(center_y - (h/2))\n",
    "            \n",
    "            boxes.append([x,y,w,h])\n",
    "            confidences.append(float(confidence))\n",
    "            class_ids.append(class_id)\n",
    "print(boxes) #printing the bounding boxes values for each object\n",
    "print(confidences) # also it's respected confidences\n",
    "indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5,0.4)\n",
    "print(indexes.flatten())\n",
    "\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "colors = np.random.uniform(0,255,size = (len(boxes),3)) \n",
    "\n",
    "for i in indexes.flatten():\n",
    "    x,y,w,h = boxes[i]\n",
    "    label = str(classes[class_ids[i]])\n",
    "    confidence = str(round(confidences[i],2))\n",
    "    color = colors[i]\n",
    "    cv2.rectangle(image,(x,y),(x+w,y+h),color,2)\n",
    "    cv2.putText(image,label+\" \" + confidence, (x,y+20),font,2,(255,255,255),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final image output with prediction of yolo\n",
    "cv2.imshow(\"image\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
